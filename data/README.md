# Data Directory Structure

This document explains the data directory structure for the DayDreaming Dagster Pipeline project.

## Directory Overview

The data directory follows a numbered pipeline structure that represents the flow of data through the system:

```
data/
├── 1_raw/          # Input data (tracked in git)
├── cohorts/        # Cohort manifests and membership (tracked in git)
├── 3_generation/   # LLM generation outputs (not tracked)
├── 4_evaluation/   # LLM evaluation outputs (not tracked)  
├── 5_parsing/      # Parsed evaluation results (not tracked)
├── 6_summary/      # Summary and analysis results (not tracked)
└── 7_reporting/    # Error logs and reports (not tracked)
```

## Directory Details

### 1_raw/ (Input Data - Tracked)
**Purpose**: Source data that defines the experiment parameters

**Contents**:
- `concepts/` - Concept definitions and descriptions at different levels (sentence, paragraph, article)
  - `concepts_metadata.csv` - Concept metadata with active/inactive flags
  - `descriptions-*/` - Concept description files organized by detail level
- `*_templates.csv` - Template metadata with active/inactive flags
- `*_templates/` - Jinja2 prompt template files
- `llm_models.csv` - Available LLM models with generation/evaluation flags

**Tracking**: ✅ Tracked in git (these are the experiment definitions)

### cohorts/ (Cohorts & Membership - Tracked)  
**Purpose**: Authoritative cohort manifest and normalized membership; registers dynamic partitions

**Contents**:
- `<cohort_id>/manifest.json` — deterministic manifest (combos/templates/models)
- `<cohort_id>/membership.csv` — normalized rows with parent links:
  - Columns: `stage, gen_id, cohort_id, parent_gen_id, combo_id, template_id, llm_model_id`
- `../2_tasks/selected_combo_mappings.csv` — curated combo selection (optional input)

**Tracking**: ✅ Tracked in git (reproducible cohort definitions)

**Generated by**: `cohort_id`, `content_combinations`, and `cohort_membership` assets

### 3_generation/ (LLM Generation - Not Tracked)
**Purpose**: LLM-generated responses to concept combination prompts  

**Contents**:
- `generation_prompts/` - Generated prompts (one file per partition)
- `generation_responses/` - LLM responses to prompts (one file per partition)

**Tracking**: ❌ Not tracked (large, regenerable, API-dependent)

**Generated by**: `group:generation_draft` and `group:generation_essays` assets (legacy `generation_links` supported)

### 4_evaluation/ (LLM Evaluation - Not Tracked)
**Purpose**: LLM-based evaluation of generation responses

**Contents**:
- `evaluation_prompts/` - Generated evaluation prompts (one file per partition)  
- `evaluation_responses/` - LLM evaluation responses (one file per partition)

**Tracking**: ❌ Not tracked (large, regenerable, API-dependent)

**Generated by**: `group:evaluation` assets

### 5_parsing/ (Parsed Results - Not Tracked)
**Purpose**: Structured data extracted from LLM evaluation responses

**Contents**:
- `parsed_scores.csv` - Extracted scores and metadata from evaluation responses
- Other parsed result files as needed

**Tracking**: ❌ Not tracked (derived from 4_evaluation/)

**Generated by**: `group:results_processing` assets

### 6_summary/ (Analysis Results - Not Tracked)  
**Purpose**: Final analysis and summary of experiment results

**Contents**:
- `final_results.csv` - Aggregated experiment results
- `perfect_score_paths.csv` - Analysis of perfect scoring combinations
- Other summary and analysis files

**Tracking**: ❌ Not tracked (derived from 5_parsing/)

**Generated by**: `group:results_processing` assets

### 7_reporting/ (Error Logs - Not Tracked)
**Purpose**: Error logs and diagnostic information

**Contents**:
- Error logs from failed LLM calls
- Diagnostic reports
- Processing statistics

**Tracking**: ❌ Not tracked (operational data)

**Generated by**: Various assets for error reporting

## Data Flow

```
1_raw → 2_tasks → 3_generation → 4_evaluation → 5_parsing → 6_summary
   ↓                                                           ↓
   └─ Experiment Definition                              Final Results ─┘
```

## Tracking Strategy

**What's Tracked**:
- `1_raw/` - Experiment definitions (concepts, templates, models)
- `cohorts/<cohort_id>/` - Cohort manifest and membership
- `2_tasks/selected_combo_mappings.csv` - optional curated selection

**What's Not Tracked**:  
- `3_generation/` through `7_reporting/` - Large, regenerable, or operational data
- See `.gitignore` for complete list

**Rationale**: The tracked data allows complete reproduction of experiments, while the untracked data can be regenerated from the tracked definitions.

## Usage Notes

- Raw and cohort assets auto-update when `data/1_raw/**/*` changes (daemon required). Start Dagster with the daemon to keep them fresh.
- Seed: materialize `cohort_id,cohort_membership` once to register partitions for the active cohort.
- The pipeline creates directories automatically as needed
- Use Dagster UI to monitor data generation progress
- Large datasets in generation/evaluation folders can be safely deleted and regenerated

## Data Retention and Overwrite Behavior

This project intentionally separates tracked, reproducible definitions from untracked, regenerable artifacts.

- **Tracked (retained across materializations)**:
- `1_raw/` CSVs and `cohorts/<cohort_id>/membership.csv` are overwritten in-place by their assets to reflect the latest selection logic, but are version-controlled in git. You can revert if needed. Note: `2_tasks/selected_combo_mappings.csv` is regenerated from active concepts when `selected_combo_mappings` is materialized; skip this asset if you want to keep a curated file intact.
  - `data/combo_mappings.csv` is append-only and is never cleared automatically. It preserves stable `combo_id` mappings for cross-experiment reproducibility.

- **Untracked (safe to delete and regenerate)**:
  - `3_generation/` prompts and responses
  - `4_evaluation/` prompts and responses
  - `5_parsing/` parsed results
  - `6_summary/` analysis outputs
  - `7_reporting/` error logs

### What gets deleted or reset when you (re)materialize

- Dynamic partitions for draft/essay/evaluation are (re)registered by `cohort_membership`. Existing cohort partitions are pruned cohort‑scoped before re‑registering.
- CSV outputs (membership, selection) are rewritten by their producing assets.
- Files under `3_generation/` and `4_evaluation/` are not deleted by the pipeline. Existing files remain on disk unless you remove them manually.

### Overwrite guards for LLM artifacts

- Prompts (`3_generation/generation_prompts`, `4_evaluation/evaluation_prompts`) are configured to allow overwrite so they reflect the current template code.
- Responses (`3_generation/generation_responses`, `4_evaluation/evaluation_responses`) are protected against overwrite by default. If a response file already exists for a partition key, the run will fail with a clear error instead of silently overwriting. To regenerate, either:
  - delete the specific file(s), or
  - change the partition key (e.g., different template/model), or
  - intentionally configure the IO manager with `overwrite=True` (not recommended for responses).

### Stable partition keys and filenames

- Filenames are derived from partition keys. Generation partitions follow `{combo_id}_{template_id}_{model_id}` and evaluation partitions append evaluation identifiers. With stable combo IDs (`combo_v1_<12-hex>`), filenames are deterministic and do not collide across runs unless the same task is intentionally repeated.

### Full reset (keeping raw data)

To start fresh while retaining experiment definitions, you can remove generated artifacts:

```bash
rm -rf data/cohorts/*
rm -rf data/3_generation/*
rm -rf data/4_evaluation/*
rm -rf data/5_parsing/*
rm -rf data/6_summary/*
rm -rf data/7_reporting/*
```

Recreate cohort membership and downstream data by materializing (seed once; daemon handles updates):

```bash
uv run dagster asset materialize --select "cohort_id,cohort_membership,content_combinations" -f daydreaming_dagster/definitions.py
```
